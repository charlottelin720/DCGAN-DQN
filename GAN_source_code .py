# -*- coding: utf-8 -*-
"""HW3_0853420_林若瑜.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zvqg4WY0MrkjTwBUnCRe-GO8LVUrdzZQ
"""

#from google.colab import drive
import pandas as pd


#drive.mount('/content/drive/')# 此處需要登入google帳號
## 獲取授權碼之後輸入即可連動雲端硬碟
#
#from google.colab import drive
#drive.mount('/content/drive')

# import zipfile

# zip_ref = zipfile.ZipFile("/content/drive/My Drive/img_align_celeba.zip", 'r')
# zip_ref.extractall("/content/drive/My Drive/HW3_data")
# zip_ref.close()

import os, time, sys
import matplotlib.pyplot as plt
import itertools
import pickle
import imageio
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.autograd import Variable

import torch.nn as nn

# Number of channels in the training images. For color images this is 3
nc = 3

# Size of z latent vector (i.e. size of generator input)
nz = 100

# Size of feature maps in generator
ngf = 64

# Size of feature maps in discriminator
ndf = 64


# Generator Code

class Generator(nn.Module):
    def __init__(self, ngpu):
        super(Generator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # state size. (ngf*8) x 4 x 4
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # state size. (ngf*4) x 8 x 8
            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # state size. (ngf*2) x 16 x 16
            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # state size. (ngf) x 32 x 32
            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (nc) x 64 x 64
        )

    def forward(self, input):
        return self.main(input)
    
    
    
class Discriminator(nn.Module):
    def __init__(self, ngpu):
        super(Discriminator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*8) x 4 x 4
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        return self.main(input)

import os
import matplotlib.pyplot as plt
# from scipy.misc import imresize
from PIL import Image
import numpy as np
import torch, os, glob, time
from torchvision import datasets, transforms
from torchvision.utils import save_image
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import torchvision.utils
#from __future__ import print_function

# training parameters
BATCH_SIZE = 128
lr = 0.0002
train_epoch = 20

# data_loc = '/content/drive/My Drive/HW3_data'
# transform = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
# dataset = datasets.ImageFolder(data_loc, transform)
# data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)

transform = transforms.Compose([transforms.Resize((64, 64)),
                                transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5),
                                                    (0.5, 0.5, 0.5))])

#data_loc = 'C:\Users\user\Desktop\HW3_data'



dataset = datasets.ImageFolder(r'C:\Users\user\Desktop\HW3_data', transform)
# Create the dataloader
dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)
print('done')




#%matplotlib inline
import argparse
import os
import random
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import argparse
from IPython.display import HTML
# from Model import *

beta1 = 0.5

# Set random seed for reproducibility
manualSeed = 999
#manualSeed = random.randint(1, 10000) # use if you want new results
print("Random Seed: ", manualSeed)
random.seed(manualSeed)
torch.manual_seed(manualSeed)

ngpu = 1
# device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")
#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
#torch.cuda.set_device(0)
device = 'cpu'


# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# # torch.cuda.set_device(0)




def common_arg_parser():
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--dataroot', default='data/celeba', type=str)
    parser.add_argument('--batch_size', default=128, type=int)
    parser.add_argument('--image_size', default=64, type=int)
    parser.add_argument('--num_epochs', default=5, type=int)
    parser.add_argument('--lr', default=0.0002, type=float)
    

    return parser



def train(dataloader, generator, discriminator, optimizer_g, optimizer_d, criterion, num_epochs):
    
    netG = Generator(ngpu).to(device)
    netD = Discriminator(ngpu).to(device)
    real_label = 1
    fake_label = 0
    optimizer_g = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))
    optimizer_d = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))
    criterion = nn.BCELoss()
    fixed_noise = torch.randn(64, nz, 1, 1, device=device)
    img_list = []
    G_losses = []
    D_losses = []
    iters = 0
    print('Start!')

    # Each epoch, we have to go through every data in dataset
    for epoch in range(num_epochs):
        # Each iteration, we will get a batch data for training
        for i, data in enumerate(dataloader, 0):
            # Update D network
            # initialize gradient for network
            # send the data into device for computation
            netD.zero_grad()
            real_cpu = data[0].to(device)
            b_size = real_cpu.size(0)
            label = torch.full((b_size,), real_label, device=device)
            output = netD(real_cpu).view(-1)

            # Send data to discriminator and calculate the loss and gradient
            # For calculate loss, you need to create label for your data
            errD_real = criterion(output, label)
            errD_real.backward()
            D_x = output.mean().item()

            ## Using Fake data, other steps are the same.
            # Generate a batch fake data by using generator
            noise = torch.randn(b_size, nz, 1, 1, device=device)
            fake = netG(noise)
            label.fill_(fake_label)
            output = netD(fake.detach()).view(-1)

            errD_fake = criterion(output, label)
            errD_fake.backward()

            D_G_z1 = output.mean().item()
            errD = errD_real + errD_fake
            optimizer_d.step()

            # Update G network
            netG.zero_grad()
            label.fill_(real_label)
            output = netD(fake).view(-1)
            errG = criterion(output, label)
            errG.backward()
            D_G_z2 = output.mean().item()
            optimizer_g.step()

            # Output training stats
            if i % 50 == 0:
                print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f' % (epoch, num_epochs, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

            # Save Losses for plotting later
            G_losses.append(errG.item())
            D_losses.append(errD.item())

            # Check how the generator is doing by saving G's output on fixed_noise
            if (iters % 500 == 0) or ((epoch == num_epochs - 1) and (i == len(dataloader) - 1)):
                with torch.no_grad():
                    fake = netG(fixed_noise).detach().cpu()

                img_list.append(vutils.make_grid(fake, padding=2, normalize=True))

            iters += 1


    # Remember to save all things you need after all batches finished!!!
    torch.save(netD, 'netD.pkl')
    torch.save(netG, 'netG.pkl')
#    np.save('G_losses.npy',G_losses)
#    np.save('D_losses.npy',D_losses)
#    np.save('img_list.npy',img_list)

    return G_losses, D_losses, img_list




            

            
  
            


        
            
            
            
            # Send data to discriminator and calculate the loss and gradient
            # For calculate loss, you need to create label for your data

            
            # Update your network

            
            
            # Record your loss every iteration for visualization
            
            
            # Use this function to output training procedure while training
            # You can also use this function to save models and samples after fixed number of iteration
         
     
            
        
        

def main(args):
    # Create the dataset by using ImageFolder(get extra point by using customized dataset)
    # remember to preprocess the image by using functions in pytorch
    transform = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

    data_loc = r'C:\Users\user\Desktop\HW3_data'
    dataset = datasets.ImageFolder(data_loc, transform)
    # Create the dataloader
    dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)
    print('done')
    

    # Create the generator and the discriminator()
    # Initialize them 
    # Send them to your device
    netG = Generator(ngpu).to(device)
    netD = Discriminator(ngpu).to(device)


    # # Loss fuG_out_D_intion

    fixed_noise = torch.randn(64, nz, 1, 1, device=device)

    real_label = 1
    fake_label = 0

    

    # Setup optimizers for both G and D and setup criterion at the same time
    optimizer_g = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))
    optimizer_d = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))
    criterion = nn.BCELoss()
    
    
    # Start training~~
    
    # train(dataloader, netG, netD, optimizer_g, optimizer_d, criterion, args.num_epochs)
    G_losses, D_losses, img_list = train(dataloader, netG, netD, optimizer_g, optimizer_d, criterion, 5)
#    np.save('G_losses.npy',G_losses)
#    np.save('D_losses.npy',D_losses)
#    np.save('img_list.npy',img_list)
    
    return G_losses, D_losses, img_list




if __name__ == '__main__':
    args = common_arg_parser()
    G_losses, D_losses, img_list = main(args)

import numpy as np
import matplotlib.pyplot as plt
from matplotlib import animation

##Write down your visualization code here

## Animation for your generation
##input : image_list (size = (the number of sample times, how many samples created each time, image )   )
#img_list = []


fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)

plt.show()
# https://matplotlib.org/api/_as_gen/matplotlib.animation.Animation.html#matplotlib.animation.Animation.save



fig, ax = plt.subplots(1, 1)
fig.set_size_inches(8, 4)
ax.set_title('Generator')
ax.set_xlabel('iteration')
ax.set_ylabel('Loss')
ax.plot(G_losses)


fig, ax = plt.subplots(1, 1)
fig.set_size_inches(8, 4)
ax.set_title('Discriminator')
ax.set_xlabel('iteration')
ax.set_ylabel('Loss')
ax.plot(D_losses)

# plt.legend(loc=1)

def show_image(imgs, title):
        x = np.transpose(torchvision.utils.make_grid(imgs[1:2],1,1), (1, 2, 0))
        print(title)
        plt.imshow(x)
#
#sample = torch.randn(BATCH_SIZE, 128).to(device)
## decoder(x, batch_size):
#real_cpu = data[0].to(device)
#imgs = model.decoder(sample, batch_size=BATCH_SIZE).cpu()
#
show_image(img_list, 'Samples drawn from DCGAN')




